{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "547dfe85",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Flow Matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cb51734b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import torch\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from Engine import *\n",
    "from pathlib import Path\n",
    "from torchdyn.core import NeuralODE\n",
    "from torchdyn.datasets import generate_moons"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b241a60",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Conditional Flow Matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "759956c8-ce9d-4bb4-a9ad-7f83e19652bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def trajectories(model, x_0, steps):\n",
    "    x_t = x_0\n",
    "    delta_t = 1 / steps\n",
    "    trajectory = [x_t.cpu().numpy()]\n",
    "    for k in range(steps):\n",
    "        t = k / steps * torch.ones(x_t.shape[0], 1)\n",
    "        v_t = model(torch.cat([x_t, t], dim=-1))\n",
    "        x_t = x_t + v_t * delta_t\n",
    "        trajectory.append(x_t.cpu().numpy())\n",
    "\n",
    "    trajectory = np.array(trajectory)\n",
    "    return torch.tensor(trajectory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "176eb7fe",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5000: loss 10.423 time 8.56\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'torch_wrapper' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[0;32m<timed exec>:28\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'torch_wrapper' is not defined"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "savedir = os.path.join(os.getcwd(), \"Results/CFM\")\n",
    "Path(savedir).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "sigma = 0.1\n",
    "dim = 2\n",
    "batch_size = 256\n",
    "model = MLP(dim=dim, time_varying=True)\n",
    "optimizer = torch.optim.Adam(model.parameters())\n",
    "FM = CFM(sigma=sigma)\n",
    "criterion = torch.nn.MSELoss()\n",
    "\n",
    "start = time.time()\n",
    "for k in tqdm(range(20000)):\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    x0 = sample_8gaussians(batch_size)\n",
    "    x1 = sample_moons(batch_size)\n",
    "\n",
    "    t, xt, ut = FM.sample_location_and_conditional_flow(x0, x1)\n",
    "\n",
    "    vt = model(torch.cat([xt, t[:, None]], dim=-1))\n",
    "    loss = criterion(vt, ut)\n",
    "\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    if (k + 1) % 5000 == 0:\n",
    "        end = time.time()\n",
    "        print(f\"{k+1}: loss {loss.item():0.3f} time {(end - start):0.2f}\")\n",
    "        start = end\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            traj = trajectories(model, sample_8gaussians(1024), steps=100)\n",
    "            plot_trajectories(traj=traj)\n",
    "            evaluate(traj[-1], sample_moons(1024))\n",
    "\n",
    "torch.save(model, f\"{savedir}/CFM.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e8057b9",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Optimal Transport Conditional Flow Matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aed74817",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[0;32m<timed exec>:15\u001b[0m\n",
      "File \u001b[0;32m~/Vault/XVFM/Engine/FM.py:57\u001b[0m, in \u001b[0;36mOT_CFM.sample_location_and_conditional_flow\u001b[0;34m(self, x0, x1, t, return_noise)\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msample_location_and_conditional_flow\u001b[39m(\u001b[38;5;28mself\u001b[39m, x0, x1, t\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, return_noise\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[0;32m---> 57\u001b[0m     x0, x1 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mot_sampler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msample_plan\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx0\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx1\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     58\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39msample_location_and_conditional_flow(x0, x1, t, return_noise)\n",
      "File \u001b[0;32m~/Vault/XVFM/Engine/OT.py:74\u001b[0m, in \u001b[0;36mOTSampler.sample_plan\u001b[0;34m(self, x0, x1, replace)\u001b[0m\n\u001b[1;32m     73\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msample_plan\u001b[39m(\u001b[38;5;28mself\u001b[39m, x0, x1, replace\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[0;32m---> 74\u001b[0m     pi \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_map\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx0\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx1\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     75\u001b[0m     i, j \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msample_map(pi, x0\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m], replace\u001b[38;5;241m=\u001b[39mreplace)\n\u001b[1;32m     77\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m x0[i], x1[j]\n",
      "File \u001b[0;32m~/Vault/XVFM/Engine/OT.py:50\u001b[0m, in \u001b[0;36mOTSampler.get_map\u001b[0;34m(self, x0, x1)\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnormalize_cost:\n\u001b[1;32m     48\u001b[0m     M \u001b[38;5;241m=\u001b[39m M \u001b[38;5;241m/\u001b[39m M\u001b[38;5;241m.\u001b[39mmax()  \n\u001b[0;32m---> 50\u001b[0m p \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mot_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mM\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdetach\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcpu\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnumpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m np\u001b[38;5;241m.\u001b[39mall(np\u001b[38;5;241m.\u001b[39misfinite(p)):\n\u001b[1;32m     52\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mERROR: p is not finite\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/XVFM/lib/python3.12/site-packages/ot/lp/__init__.py:353\u001b[0m, in \u001b[0;36memd\u001b[0;34m(a, b, M, numItermax, log, center_dual, numThreads, check_marginals)\u001b[0m\n\u001b[1;32m    349\u001b[0m bsel \u001b[38;5;241m=\u001b[39m b \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m    351\u001b[0m numThreads \u001b[38;5;241m=\u001b[39m check_number_threads(numThreads)\n\u001b[0;32m--> 353\u001b[0m G, cost, u, v, result_code \u001b[38;5;241m=\u001b[39m \u001b[43memd_c\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mM\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnumItermax\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnumThreads\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    355\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m center_dual:\n\u001b[1;32m    356\u001b[0m     u, v \u001b[38;5;241m=\u001b[39m center_ot_dual(u, v, a, b)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "savedir = os.path.join(os.getcwd(), \"Results/OT-CFM\")\n",
    "Path(savedir).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "sigma = 0.1\n",
    "dim = 2\n",
    "batch_size = 256\n",
    "model = MLP(dim=dim, time_varying=True)\n",
    "optimizer = torch.optim.Adam(model.parameters())\n",
    "FM = OT_CFM(sigma=sigma)\n",
    "criterion = torch.nn.MSELoss()\n",
    "\n",
    "start = time.time()\n",
    "for k in tqdm(range(20000)):\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    x0 = sample_8gaussians(batch_size)\n",
    "    x1 = sample_moons(batch_size)\n",
    "\n",
    "    t, xt, ut = FM.sample_location_and_conditional_flow(x0, x1)\n",
    "\n",
    "    vt = model(torch.cat([xt, t[:, None]], dim=-1))\n",
    "    loss = criterion(vt, ut)\n",
    "\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    if (k + 1) % 5000 == 0:\n",
    "        end = time.time()\n",
    "        print(f\"{k+1}: loss {loss.item():0.3f} time {(end - start):0.2f}\")\n",
    "        start = end\n",
    "\n",
    "        with torch.no_grad():\n",
    "            traj = trajectories(model, sample_8gaussians(1024), steps=100)\n",
    "            plot_trajectories(traj=traj.cpu().numpy())\n",
    "            evaluate(traj[-1].cpu(), sample_moons(1024))\n",
    "\n",
    "torch.save(model, f\"{savedir}/OT-CFM.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00fc23dc",
   "metadata": {},
   "source": [
    "### Variational Flow Matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d98d9bab-0874-4a7a-a85f-6b637f9436b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def trajectories(model, x_0, steps):\n",
    "    xt = x_0\n",
    "    delta_t = 1 / steps\n",
    "    trajectory = [xt.cpu().numpy()]\n",
    "    for k in range(steps):\n",
    "        t = k / steps * torch.ones(xt.shape[0], 1)\n",
    "        x1 = model(torch.cat([xt, t], dim=-1))\n",
    "        v_t = (x1 - xt) / (1 - t)\n",
    "        xt = xt + v_t * delta_t\n",
    "        trajectory.append(xt.cpu().numpy())\n",
    "\n",
    "    trajectory = np.array(trajectory)\n",
    "    return torch.tensor(trajectory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cc1b2ada",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[0;32m<timed exec>:25\u001b[0m\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/XVFM/lib/python3.12/site-packages/torch/_tensor.py:466\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    463\u001b[0m     \u001b[38;5;66;03m# All strings are unicode in Python 3.\u001b[39;00m\n\u001b[1;32m    464\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_tensor_str\u001b[38;5;241m.\u001b[39m_str(\u001b[38;5;28mself\u001b[39m, tensor_contents\u001b[38;5;241m=\u001b[39mtensor_contents)\n\u001b[0;32m--> 466\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mbackward\u001b[39m(\n\u001b[1;32m    467\u001b[0m     \u001b[38;5;28mself\u001b[39m, gradient\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, retain_graph\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, create_graph\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, inputs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    468\u001b[0m ):\n\u001b[1;32m    469\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Computes the gradient of current tensor wrt graph leaves.\u001b[39;00m\n\u001b[1;32m    470\u001b[0m \n\u001b[1;32m    471\u001b[0m \u001b[38;5;124;03m    The graph is differentiated using the chain rule. If the tensor is\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    513\u001b[0m \u001b[38;5;124;03m            used to compute the attr::tensors.\u001b[39;00m\n\u001b[1;32m    514\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m    515\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "savedir = os.path.join(os.getcwd(), \"Results/VFM\")\n",
    "Path(savedir).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "sigma = 0.1\n",
    "dim = 2\n",
    "batch_size = 256\n",
    "model = MLP(dim=dim, time_varying=True)\n",
    "optimizer = torch.optim.Adam(model.parameters())\n",
    "FM = CFM(sigma=sigma)\n",
    "# criterion = torch.nn.MSELoss()\n",
    "criterion = torch.nn.GaussianNLLLoss()\n",
    "\n",
    "start = time.time()\n",
    "for k in tqdm(range(20000)):\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    x0 = sample_8gaussians(batch_size)\n",
    "    x1 = sample_moons(batch_size)\n",
    "\n",
    "    t, xt, _ = FM.sample_location_and_conditional_flow(x0, x1)\n",
    "\n",
    "    var = torch.ones(batch_size, dim, requires_grad=False) * sigma**2\n",
    "    var.requires_grad_(False)\n",
    "\n",
    "    vt = model(torch.cat([xt, t[:, None]], dim=-1))\n",
    "    # loss = criterion(vt, x1)\n",
    "    loss = criterion(vt, x1, var)\n",
    "\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    if (k + 1) % 5000 == 0:\n",
    "        end = time.time()\n",
    "        print(f\"{k+1}: loss {loss.item():0.3f} time {(end - start):0.2f}\")\n",
    "        start = end\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            traj = trajectories(model, sample_8gaussians(1024), steps=100)\n",
    "            plot_trajectories(traj=traj)\n",
    "            evaluate(traj[-1], sample_moons(1024))\n",
    "\n",
    "torch.save(model, f\"{savedir}/VFM.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e4639b0",
   "metadata": {},
   "source": [
    "### Stochastic Gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24e951dd-224a-48bc-8b18-31bb446c890f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLPWithScore(torch.nn.Module):\n",
    "    def __init__(self, dim, time_varying):\n",
    "        super(MLPWithScore, self).__init__()\n",
    "        self.mu = MLP(dim=dim, time_varying=time_varying)\n",
    "        self.score = MLP(dim=dim, time_varying=time_varying)\n",
    "\n",
    "    def forward(self, x):\n",
    "        mu = self.mu(x)\n",
    "        score = self.score(x)\n",
    "        return mu, score\n",
    "\n",
    "\n",
    "def g_t(t):\n",
    "    return torch.exp(t)\n",
    "\n",
    "\n",
    "def trajectories(model, x_0, steps):\n",
    "    xt = x_0\n",
    "    delta_t = 1 / steps\n",
    "    trajectory = [xt.cpu().numpy()]\n",
    "    for k in range(steps):\n",
    "        t = k / steps * torch.ones(xt.shape[0], 1)\n",
    "        mu_theta, score_theta = model(torch.cat([xt, t], dim=-1))\n",
    "        gt = g_t(t)\n",
    "        v_tilde = ((mu_theta - xt) / (1 - t)) + ((gt**2 / 2) * score_theta)\n",
    "        xt = xt + v_tilde * delta_t\n",
    "        trajectory.append(xt.cpu().numpy())\n",
    "\n",
    "    trajectory = np.array(trajectory)\n",
    "    return torch.tensor(trajectory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac215707",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "savedir = os.path.join(os.getcwd(), \"Results/SG\")\n",
    "Path(savedir).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "sigma = 0.1\n",
    "dim = 2\n",
    "batch_size = 256\n",
    "model = MLPWithScore(dim=dim, time_varying=True)\n",
    "optimizer = torch.optim.Adam(model.parameters())\n",
    "FM = CFM(sigma=sigma)\n",
    "criterion_v = torch.nn.GaussianNLLLoss()\n",
    "criterion_s = torch.nn.MSELoss()\n",
    "\n",
    "start = time.time()\n",
    "for k in tqdm(range(20000)):\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    x0 = sample_8gaussians(batch_size)\n",
    "    x1 = sample_moons(batch_size)\n",
    "\n",
    "    t, xt, _ = FM.sample_location_and_conditional_flow(x0, x1)\n",
    "\n",
    "    xt.requires_grad_(True)\n",
    "\n",
    "    var = torch.ones(batch_size, dim, requires_grad=False) * sigma**2\n",
    "    var.requires_grad_(False)\n",
    "    gt = g_t(t)\n",
    "\n",
    "    mu_theta, score_theta = model(torch.cat([xt, t[:, None]], dim=-1))\n",
    "    loss_v = criterion_v(mu_theta, x1, var / pad_t_like_x(gt, var)**2)\n",
    "\n",
    "    score_true = torch.autograd.grad((x1 - xt).sum(), xt, create_graph=True)[0]\n",
    "    loss_s = criterion_s(score_theta, score_true / pad_t_like_x(gt, score_true))\n",
    "    \n",
    "    loss = loss_v + loss_s\n",
    "\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    if (k + 1) % 5000 == 0:\n",
    "        end = time.time()\n",
    "        print(f\"{k+1}: loss {loss.item():0.3f} time {(end - start):0.2f}\")\n",
    "        start = end\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            traj = trajectories(model, sample_8gaussians(1024), steps=100)\n",
    "            plot_trajectories(traj=traj)\n",
    "            evaluate(traj[-1], sample_moons(1024))\n",
    "\n",
    "torch.save(model, f\"{savedir}/SG.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3532d9a",
   "metadata": {},
   "source": [
    "### VFM with learned sigma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb522137-17b0-48e2-ab84-fd1c036dfe7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def trajectories(model, x_0, steps):\n",
    "    xt = x_0\n",
    "    delta_t = 1 / steps\n",
    "    trajectory = [xt.cpu().numpy()]\n",
    "    for k in range(steps):\n",
    "        t = k / steps * torch.ones(xt.shape[0], 1)\n",
    "        x1 = model(torch.cat([xt, t], dim=-1))\n",
    "        v_t = (x1 - xt) / (1 - t)\n",
    "        xt = xt + v_t * delta_t\n",
    "        trajectory.append(xt.cpu().numpy())\n",
    "\n",
    "    trajectory = np.array(trajectory)\n",
    "    return torch.tensor(trajectory)\n",
    "\n",
    "\n",
    "class SigmaMLP(MLP):\n",
    "    def __init__(self, dim, out_dim=None, w=64, time_varying=False):\n",
    "        super().__init__(dim, out_dim=out_dim, w=w, time_varying=time_varying)\n",
    "        self.last_filter = torch.nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        pred = self.net(x)\n",
    "        pred = self.last_filter(pred)\n",
    "        return pred\n",
    "\n",
    "    savedir = os.path.join(os.getcwd(), \"Results/SVFM\")\n",
    "    Path(savedir).mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "772b5a54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5000: loss 504.400 time 8.86\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'torch_wrapper' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 32\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mk\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: loss \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mloss\u001b[38;5;241m.\u001b[39mitem()\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m0.3f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m time \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m(end\u001b[38;5;250m \u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;250m \u001b[39mstart)\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m0.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     31\u001b[0m start \u001b[38;5;241m=\u001b[39m end\n\u001b[0;32m---> 32\u001b[0m node \u001b[38;5;241m=\u001b[39m NeuralODE(\u001b[43mtorch_wrapper\u001b[49m(model), solver\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124meuler\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     33\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[1;32m     34\u001b[0m     traj \u001b[38;5;241m=\u001b[39m node\u001b[38;5;241m.\u001b[39mtrajectory(\n\u001b[1;32m     35\u001b[0m         sample_8gaussians(\u001b[38;5;241m1024\u001b[39m),\n\u001b[1;32m     36\u001b[0m         t_span\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mlinspace(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m100\u001b[39m),\n\u001b[1;32m     37\u001b[0m     )\n",
      "\u001b[0;31mNameError\u001b[0m: name 'torch_wrapper' is not defined"
     ]
    }
   ],
   "source": [
    "%% time\n",
    "\n",
    "dim = 2\n",
    "batch_size = 256\n",
    "noise = 0.2\n",
    "\n",
    "model = MLP(dim=dim, time_varying=True)\n",
    "sigma = torch.nn.Parameter(torch.rand(1))\n",
    "optimizer = torch.optim.Adam([param for param in model.parameters()] + [sigma])\n",
    "FM = CFM()\n",
    "criterion = torch.nn.GaussianNLLLoss()\n",
    "\n",
    "\n",
    "start = time.time()\n",
    "for k in tqdm(range(20000)):\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    x0 = sample_8gaussians(batch_size)\n",
    "    x1 = sample_moons(batch_size, noise=noise)\n",
    "\n",
    "    t, xt, _ = FM.sample_location_and_conditional_flow(x0, x1)\n",
    "\n",
    "    mu_theta = model(torch.cat([xt, t[:, None]], dim=-1))\n",
    "\n",
    "    var = torch.ones(batch_size, dim) * (sigma**2)\n",
    "\n",
    "    loss = criterion(mu_theta, x1, var)\n",
    "\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    if (k + 1) % 5000 == 0:\n",
    "        end = time.time()\n",
    "        print(f\"{k+1}: loss {loss.item():0.3f} time {(end - start):0.2f}\")\n",
    "        start = end\n",
    "\n",
    "        with torch.no_grad():\n",
    "            traj = trajectories(model, sample_8gaussians(1024), steps=100)\n",
    "            plot_trajectories(traj=traj.cpu().numpy(), output=f\"{savedir}/SVFM_{k+1}.png\")\n",
    "            evaluate(traj[-1].cpu(), sample_moons(1024))\n",
    "            print(sigma)\n",
    "            \n",
    "torch.save(model, f\"{savedir}/SVFM.pt\")\n",
    "torch.save(sigma, f\"{savedir}/sigma.pt\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
